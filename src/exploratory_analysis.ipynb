{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the counts of the different classes to csv files for both train and test sets\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'D:/Memes2023_splitted/finetuning/train/'\n",
    "val_folder = 'D:/Memes2023_splitted/finetuning/val/'\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "train_meme_folders = os.listdir(train_folder)\n",
    "val_meme_folders = os.listdir(val_folder)\n",
    "train_file_counts = {meme_folder: len(os.listdir(os.path.join(train_folder, meme_folder))) for meme_folder in tqdm(train_meme_folders)}\n",
    "val_file_counts = {meme_folder: len(os.listdir(os.path.join(val_folder, meme_folder))) for meme_folder in tqdm(val_meme_folders)}\n",
    "\n",
    "#save train_file_counts as csv\n",
    "df = pd.DataFrame.from_dict(train_file_counts, orient='index')\n",
    "#key column name = Class   value column name = Count\n",
    "df = df.rename_axis('Class').reset_index().rename(columns={0: 'Count'})\n",
    "df.to_csv('train_file_counts.csv', index=False)\n",
    "\n",
    "#save val_file_counts as csv\n",
    "df = pd.DataFrame.from_dict(val_file_counts, orient='index')\n",
    "df = df.rename_axis('Class').reset_index().rename(columns={0: 'Count'})\n",
    "df.to_csv('val_file_counts.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading basics statistics of the dataset\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Train data:')\n",
    "#find minimum value of train file counts\n",
    "min_value = min(train_file_counts.values())\n",
    "print(f'Minimum value of train file counts: {min_value}')\n",
    "\n",
    "#get max value of train file counts\n",
    "max_value = max(train_file_counts.values())\n",
    "print(f'Maximum value of train file counts: {max_value}')\n",
    "\n",
    "#get mean of the values in the dict\n",
    "mean = sum(train_file_counts.values()) / len(train_file_counts)\n",
    "print(f'Mean of train file counts: {mean}')\n",
    "\n",
    "#get median of the values in the dict\n",
    "median = np.median(list(train_file_counts.values()))\n",
    "print(f'Median of train file counts: {median}')\n",
    "\n",
    "#get 75th percentile of the values in the dict\n",
    "percentile_75 = np.percentile(list(train_file_counts.values()), 75)\n",
    "print(f'75th percentile of train file counts: {percentile_75}')\n",
    "\n",
    "print('Val data:')\n",
    "#find minimum value of val file counts\n",
    "min_value = min(val_file_counts.values())\n",
    "print(f'Minimum value of val file counts: {min_value}')\n",
    "\n",
    "#get max value of val file counts\n",
    "max_value = max(val_file_counts.values())\n",
    "print(f'Maximum value of val file counts: {max_value}')\n",
    "\n",
    "#get mean of the values in the dict\n",
    "mean = sum(val_file_counts.values()) / len(val_file_counts)\n",
    "print(f'Mean of val file counts: {mean}')\n",
    "\n",
    "#get median of the values in the dict\n",
    "median = np.median(list(val_file_counts.values()))\n",
    "print(f'Median of val file counts: {median}')\n",
    "\n",
    "#get 75th percentile of the values in the dict\n",
    "percentile_75 = np.percentile(list(val_file_counts.values()), 75)\n",
    "print(f'75th percentile of val file counts: {percentile_75}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the number of images per class in the dataset\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_file_counts = pd.read_csv('C:/Users/Murgi/Documents/GitHub/meme_research/outputs/train_file_counts.csv')\n",
    "train_file_counts = {row['Class']: row['Count'] for row in train_file_counts.to_dict(orient='records')}\n",
    "\n",
    "val_file_counts = pd.read_csv('C:/Users/Murgi/Documents/GitHub/meme_research/outputs/val_file_counts.csv')\n",
    "val_file_counts = {row['Class']: row['Count'] for row in val_file_counts.to_dict(orient='records')}\n",
    "\n",
    "#Add the values of val_file_counts to train_file_counts\n",
    "combined_file_counts = {k: train_file_counts[k] + val_file_counts[k] for k in train_file_counts.keys()}\n",
    "#Sort the combined file counts\n",
    "combined_file_counts = dict(sorted(combined_file_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "#Sum of all values in combined_file_counts\n",
    "# sum_of_values = sum(combined_file_counts.values())\n",
    "# print(f'We have {sum_of_values} images in total.')\n",
    "\n",
    "#Create a bar chart of the combined file counts\n",
    "# Show only the top 20 classes\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(list(combined_file_counts.keys())[-50:], list(combined_file_counts.values())[-50:])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of images per class')\n",
    "plt.show()\n",
    "\n",
    "# Create a bar chart for the last 20 classes\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(list(combined_file_counts.keys())[:50], list(combined_file_counts.values())[:50])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of images per class')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(list(combined_file_counts.keys()), list(combined_file_counts.values()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of images per class')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dataset if there are any corrupted images to replace them\n",
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Directory where the images are stored\n",
    "train_folder = 'D:/Memes2023_splitted/finetuning/train/'\n",
    "val_folder = 'D:/Memes2023_splitted/finetuning/val/'\n",
    "\n",
    "corrupt_files = []\n",
    "\n",
    "for folder in [train_folder, val_folder]:\n",
    "    for subdir, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    img = Image.open(file_path)  # open the image file\n",
    "                    img.verify()  # verify that it is, in fact an image\n",
    "                except (IOError, SyntaxError) as e:\n",
    "                    corrupt_files.append(file_path)\n",
    "                    print('Bad file:', file_path)  # print out the names of corrupt files\n",
    "\n",
    "# Save the corrupt files to a text file\n",
    "with open('corrupt_files.txt', 'w') as f:\n",
    "    for file in corrupt_files:\n",
    "        f.write(file + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace corrupted images with their repaired versions\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "folder = 'C:/Users/Murgi/Downloads/repaired-val/repaired-val'\n",
    "# Directory where the images are stored\n",
    "corrupt_files = []\n",
    "for subdir, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                img = Image.open(file_path)  # open the image file\n",
    "                img.verify()  # verify that it is, in fact an image\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                corrupt_files.append(file_path)\n",
    "                print('Bad file:', file_path)  # print out the names of corrupt files\n",
    "\n",
    "print(corrupt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "train_folder_path = \"D:/Memes2023_splitted/finetuning/train\"\n",
    "val_folder_path = \"D:/Memes2023_splitted/finetuning/val\"\n",
    "for file in os.listdir(folder):\n",
    "    cls = file.split('_')[0]\n",
    "    class_folder_path = os.path.join(val_folder_path, cls)\n",
    "    shutil.copy(os.path.join(folder, file), os.path.join(class_folder_path, file))\n",
    "    print('File copied to', os.path.join(class_folder_path, file))    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataset to HDF5 format\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "hdf5_file_path = 'D:/Memes2023/dataset.hdf5'\n",
    "root = \"D:/Memes2023_splitted/finetuning\"\n",
    "corrupted = []\n",
    "\n",
    "def create_hdf5_file(root, hdf5_file_path):\n",
    "    # Create an HDF5 file to store the dataset\n",
    "    with h5py.File(hdf5_file_path, 'w') as f:\n",
    "        for subdir, dirs, files in tqdm(os.walk(root), total=410674):\n",
    "            for file in files:\n",
    "                try:\n",
    "                    # Ensure the file is an image\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "                        file_path = os.path.join(subdir, file)\n",
    "                        # Get the class name from the file path\n",
    "                        class_name = os.path.basename(os.path.dirname(file_path))\n",
    "                        # Open the image using PIL\n",
    "                        img = Image.open(file_path)\n",
    "                        img_arr = np.array(img)\n",
    "                        # Create a group for each class\n",
    "                        if class_name not in f:\n",
    "                            class_group = f.create_group(class_name)\n",
    "                        else:\n",
    "                            class_group = f[class_name]\n",
    "                        # Save the image to the group\n",
    "                        class_group.create_dataset(file, data=img_arr)\n",
    "                except:\n",
    "                    print(\"Corrupted file: \", file_path)\n",
    "                    corrupted.append(file_path)\n",
    "                    continue\n",
    "\n",
    "\n",
    "create_hdf5_file(root, hdf5_file_path)\n",
    "# save the corrupted files to a text file\n",
    "with open('corrupted.txt', 'w') as f:\n",
    "    for item in corrupted:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the HDF5 dataset\n",
    "-----------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of classes and images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "hdf5_file_path = 'D:/Memes2023/dataset.hdf5'\n",
    "\n",
    "with h5py.File(hdf5_file_path, 'r') as f:\n",
    "    num_classes = len(f.keys())\n",
    "    num_images = sum(len(f[class_name]) for class_name in f.keys())\n",
    "    print(f'Number of classes: {num_classes}')\n",
    "    print(f'Number of images: {num_images}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inscpecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with h5py.File(hdf5_file_path, 'r') as f:\n",
    "    # Choose a random class\n",
    "    class_name = random.choice(list(f.keys()))\n",
    "    class_group = f[class_name]\n",
    "    # Choose a random image from the class\n",
    "    image_name = random.choice(list(class_group.keys()))\n",
    "    img_data = class_group[image_name][()]\n",
    "    # Display the image\n",
    "    plt.imshow(img_data)\n",
    "    plt.title(f'Class: {class_name}, Image: {image_name}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching the paths to the images in our dataset\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm \n",
    "\n",
    "# First time only: create and save the list of image paths\n",
    "img_train_path_file = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_train_paths.pkl'\n",
    "img_val_path_file = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_val_paths.pkl'\n",
    "img_train_dir = 'D:/Memes2023_splitted/finetuning/train'\n",
    "img_val_dir = 'D:/Memes2023_splitted/finetuning/val'\n",
    "\n",
    "\n",
    "def cache_image_paths(img_dir, cache_path):\n",
    "    print(f'Caching image paths in {img_dir}')\n",
    "    img_label_pairs = []\n",
    "    for root, dirs, files in tqdm(os.walk(img_dir), total=23083):\n",
    "        for fname in files:\n",
    "            img_label_pairs.append((os.path.join(root, fname), os.path.basename(root)))\n",
    "    with open(cache_path, 'wb') as f:\n",
    "        pickle.dump(img_label_pairs, f)\n",
    "    print(f'Cached {len(img_label_pairs)} paths to {cache_path}')\n",
    "\n",
    "cache_image_paths(img_train_dir, img_train_path_file)\n",
    "cache_image_paths(img_val_dir, img_val_path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "D:/Memes2023_splitted/finetuning/train\\%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy\\%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy_0.png\n",
      "../storage/kym-datasets/Memes2023_splitted_resized/finetuning/train\\%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy\\%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy_0.png\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "img_train_path_file = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_train_paths.pkl'\n",
    "\n",
    "cache = pickle.load(open(img_train_path_file, 'rb'))\n",
    "print(type(cache))\n",
    "filenames = [x[0] for x in cache] \n",
    "print(filenames[0])\n",
    "\n",
    "file = filenames[0]\n",
    "parts = file.split('/')\n",
    "to_replace = '/'.join(parts[:3])\n",
    "replace_with = '../storage/kym-datasets/Memes2023_splitted_resized/finetuning'\n",
    "new_file = file.replace(to_replace, replace_with)\n",
    "print(new_file)\n",
    "#Try to open the image\n",
    "img = Image.open(new_file)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319466/319466 [00:00<00:00, 399424.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 319466 paths to C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_train_paths_rel.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91205/91205 [00:00<00:00, 332171.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 91205 paths to C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_val_paths_rel.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "img_train_path_file = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_train_paths.pkl'\n",
    "img_val_path_file = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_val_paths.pkl'\n",
    "\n",
    "train_rel_path_file = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_train_paths_rel.pkl'\n",
    "val_rel_path_file = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_val_paths_rel.pkl'\n",
    "\n",
    "def create_cache_with_rel_path(img_train_path_file, new_cache_file):\n",
    "    cache = pickle.load(open(img_train_path_file, 'rb'))\n",
    "    new_cache = []\n",
    "    for t in tqdm(cache):\n",
    "        file = t[0]\n",
    "        parts = file.split('/')\n",
    "        to_replace = '/'.join(parts[:3])\n",
    "        replace_with = '/storage/kym-datasets/Memes2023_splitted_resized/finetuning'\n",
    "        new_file = file.replace(to_replace, replace_with)\n",
    "        new_file = new_file.replace('\\\\', '/')\n",
    "        new_t = (new_file, t[1])\n",
    "        new_cache.append(new_t)\n",
    "    with open(new_cache_file, 'wb') as f:\n",
    "        pickle.dump(new_cache, f)\n",
    "    print(f'Cached {len(cache)} paths to {new_cache_file}')\n",
    "\n",
    "create_cache_with_rel_path(img_train_path_file, train_rel_path_file)\n",
    "create_cache_with_rel_path(img_val_path_file, val_rel_path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "('/storage/kym-datasets/Memes2023_splitted_resized/finetuning/train/%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy/%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy_0.png', '%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "img_train_path_file = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_train_paths_rel.pkl'\n",
    "\n",
    "cache = pickle.load(open(img_train_path_file, 'rb'))\n",
    "print(type(cache))\n",
    "print(cache[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "accuracies = pd.read_csv('C:/Users/Murgi/Documents/GitHub/meme_research/outputs/plots/class_accuracies.csv')\n",
    "train_counts = pd.read_csv('C:/Users/Murgi/Documents/GitHub/meme_research/outputs/train_file_counts.csv')\n",
    "val_counts = pd.read_csv('C:/Users/Murgi/Documents/GitHub/meme_research/outputs/val_file_counts.csv')\n",
    "counts = pd.merge(train_counts, val_counts, on='Class')\n",
    "train_counts.head(5)\n",
    "val_counts.head(5)\n",
    "counts.head(5)\n",
    "# Sum the counts of train and val\n",
    "counts['Total'] = counts['Count_x'] + counts['Count_y']\n",
    "accuracies['Count'] = counts['Total']\n",
    "accuracies.head(5)\n",
    "# Save the accuracies with counts\n",
    "accuracies.to_csv('C:/Users/Murgi/Documents/GitHub/meme_research/outputs/plots/class_accuracies_with_counts_train_val_splitted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('C:/Users/Murgi/Documents/GitHub/meme_research/outputs/plots/class_accuracies_with_counts.csv')  \n",
    "df.columns = ['class', 'accuracy', 'count']\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['count'], df['accuracy'])\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Number of Samples per Class (Train/Val)')\n",
    "\n",
    "# # Optionally, add a trendline\n",
    "# z = np.polyfit(df['count'], df['accuracy'], 1)\n",
    "# p = np.poly1d(z)\n",
    "# plt.plot(df['count'], p(df['count']), \"r--\")\n",
    "# What is the number of points on the plot?\n",
    "print(f'Number of points: {len(df)}')\n",
    "\n",
    "plt.show()\n",
    "# Save the plot\n",
    "plt.savefig('C:/Users/Murgi/Documents/GitHub/meme_research/outputs/plots/accuracy_vs_count_train_val_splitted.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress dataset with LZ4 algorithm\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lz4framed\n",
    "\n",
    "def compress_directory(directory_path, output_file_path):\n",
    "    compressor = lz4framed.Compressor(open(output_file_path, \"wb\"))\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        relative_path = os.path.relpath(root, directory_path)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            relative_file_path = os.path.join(relative_path, file)\n",
    "\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                while True:\n",
    "                    data = f.read(8192)\n",
    "                    if not data:\n",
    "                        break\n",
    "                    compressor.update(data, False)\n",
    "            \n",
    "            compressor.flush()\n",
    "            compressor.update(relative_file_path.encode(), False)\n",
    "    \n",
    "    compressed_data = compressor.end()\n",
    "    with open(output_file_path, \"wb\") as f:\n",
    "        f.write(compressed_data)\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "directory_path = 'C:/Users/Murgi/Documents/GitHub/meme_research/src/pHash/test_images'\n",
    "output_file = 'compressed_file.lz4'\n",
    "\n",
    "compress_directory(directory_path, output_file)\n",
    "print(f'Compressed {directory_path} to {output_file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the images to 64x64 pixels for better storage utilization\n",
    "---------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test image conversion and deconversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "test_image = 'C:/Users/Murgi/Documents/GitHub/meme_research/src/pHash/test_images/1468988563469.jpg'\n",
    "\n",
    "# Load the image\n",
    "img = PIL.Image.open(test_image)\n",
    "img.show()\n",
    "# Resize the image\n",
    "img = img.resize((224, 224))\n",
    "# Convert to numpy array\n",
    "img = np.array(img)\n",
    "# Reshape to (224, 224, 3)\n",
    "img = img.reshape((224, 224, 3))\n",
    "# Convert back to PIL image\n",
    "img = PIL.Image.fromarray(img)\n",
    "# Show the image\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def resize_and_save_images(original_dir, new_dir, size=(380, 380)):\n",
    "    # Define the image transformation\n",
    "    resize_transform = transforms.Resize(size)\n",
    "\n",
    "    # Walk through the original directory\n",
    "    for subdir, dirs, files in os.walk(original_dir):\n",
    "        for file in files:\n",
    "            input_path = os.path.join(subdir, file)\n",
    "            \n",
    "            # Prepare the output subdirectory, preserving the folder structure\n",
    "            rel_path = os.path.relpath(subdir, original_dir)  # get the relative path\n",
    "            outdir = os.path.join(new_dir, rel_path)  # prepare the output directory path\n",
    "            os.makedirs(outdir, exist_ok=True)  # ensure the output directory exists\n",
    "\n",
    "            # Open and resize the image\n",
    "            try:\n",
    "                img = Image.open(input_path).convert('RGB')\n",
    "                resized_img = resize_transform(img)\n",
    "\n",
    "                # Save the resized image to the new directory\n",
    "                output_path = os.path.join(outdir, file)                \n",
    "                resized_img.save(output_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Unable to process file {input_path}. Error: {e}\")\n",
    "\n",
    "# Use the function\n",
    "print('Started resizing images')\n",
    "resize_and_save_images('D:/Memes2023_splitted', 'D:/Memes2023_splitted_resized')\n",
    "print('Done with kym dataset')\n",
    "resize_and_save_images('D:/Memes2022Final2', 'D:/Memes2022Final2_resized')\n",
    "print('Done with reddit dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "kym_memes = \"D:/Memes2023_splitted_resized/finetuning\"\n",
    "reddit_memes = \"D:/Memes2022Final2_resized\"\n",
    "\n",
    "kym_captions = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/captions/kym_captions.txt'\n",
    "reddit_captions = 'C:/Users/Murgi/Documents/GitHub/meme_research/outputs/captions/reddit_captions.txt'\n",
    "\n",
    "def caption_dataset(dataset_path, output_path):\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                try:\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    image = Image.open(img_path).convert(\"RGB\")\n",
    "                    image = vis_processors[\"eval\"](image).unsqueeze(0).to(device)\n",
    "                    caption = \" \".join(model.generate({\"image\": image}))\n",
    "                    # f.write(img_path + \"\\t\" + caption + \"\\n\")\n",
    "                    print(\"Captioned image: \" + img_path)\n",
    "                except:\n",
    "                    print(\"Error captioning image: \" + img_path)\n",
    "                    continue\n",
    "\n",
    "print('Captioning kym dataset...')\n",
    "caption_dataset(kym_memes, kym_captions)\n",
    "print('Captioning reddit dataset...')\n",
    "caption_dataset(reddit_memes, reddit_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/storage/kym-datasets/Memes2023_splitted_resized/finetuning/val/%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy/%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy_1.jpg', '%E2%9D%84%EF%B8%8F-u-so-icy-ima-glacier-boy')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pkl = \"C:/Users/Murgi/Documents/GitHub/meme_research/outputs/cache/image_val_paths_rel.pkl\"\n",
    "\n",
    "with open(pkl, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/Memes2022Final2_resized/2014.01.01_14.jpg</td>\n",
       "      <td>ancient-aliens</td>\n",
       "      <td>0.137078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/Memes2022Final2_resized/2014.01.01_15.jpg</td>\n",
       "      <td>ascii-normal-heart-rate</td>\n",
       "      <td>0.036212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/Memes2022Final2_resized/2014.01.01_17.gif</td>\n",
       "      <td>2019-hong-kong-anti-extradition-bill-protests</td>\n",
       "      <td>0.093999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/Memes2022Final2_resized/2014.01.01_2.jpg</td>\n",
       "      <td>2013-nsa-surveillance-scandal</td>\n",
       "      <td>0.111166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/Memes2022Final2_resized/2014.01.01_3.jpg</td>\n",
       "      <td>2010-wikipedia-fundraising-campaign</td>\n",
       "      <td>0.214086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image_path  \\\n",
       "0  D:/Memes2022Final2_resized/2014.01.01_14.jpg   \n",
       "1  D:/Memes2022Final2_resized/2014.01.01_15.jpg   \n",
       "2  D:/Memes2022Final2_resized/2014.01.01_17.gif   \n",
       "3   D:/Memes2022Final2_resized/2014.01.01_2.jpg   \n",
       "4   D:/Memes2022Final2_resized/2014.01.01_3.jpg   \n",
       "\n",
       "                                 predicted_class  probability  \n",
       "0                                 ancient-aliens     0.137078  \n",
       "1                        ascii-normal-heart-rate     0.036212  \n",
       "2  2019-hong-kong-anti-extradition-bill-protests     0.093999  \n",
       "3                  2013-nsa-surveillance-scandal     0.111166  \n",
       "4            2010-wikipedia-fundraising-campaign     0.214086  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../model_predictions_alexnet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numpy arrays from the dataframe columns\n",
    "images_done = df['image_path'].to_numpy()\n",
    "assigned_labels = df['predicted_class'].to_numpy()\n",
    "confidence_scores = df['probability'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955593,)\n"
     ]
    }
   ],
   "source": [
    "print(images_done.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1352\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(len(np.unique(assigned_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955593,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Step 5: Save results to JSON file\n",
    "print(images_done.shape)\n",
    "\n",
    "# Collecting the results\n",
    "results = dict()\n",
    "\n",
    "for path, label, confidence in zip(images_done, assigned_labels, confidence_scores):\n",
    "    if label not in results:\n",
    "        results[label] = {\"cluster_name\": label, \"images\": {}}\n",
    "    results[label][\"images\"][path] = float(confidence)  # convert numpy float to Python float\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('../outputs/clusters/jsons/model_results.json', 'w') as f:\n",
    "    json.dump(list(results.values()), f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
